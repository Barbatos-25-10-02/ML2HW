{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c402ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import re as regex\n",
    "from sklearn.neighbors import kneighbors_graph as KNN   # https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.kneighbors_graph.html\n",
    "from sklearn.neighbors import NearestNeighbors as KNN2  # https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html  and  https://stackoverflow.com/questions/21052509/sklearn-knn-usage-with-a-user-defined-metric\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.metrics.pairwise import pairwise_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190b44ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Borrowed SNE implementation bc sklearn doesn't have one\n",
    "class My_SNE:\n",
    "\n",
    "    def __init__(self, X, y=None, n_components=2, learning_rate=0.1, max_iterations=1000, step_checkpoint=20):\n",
    "        # X: rows are features and columns are samples\n",
    "        # labels y is only for plotting the embeddings --> if set None, it does not plot\n",
    "        self.n_components = n_components\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_training_images = self.X.shape[1]\n",
    "        self.data_dimension = self.X.shape[0]\n",
    "        self.max_iterations = max_iterations\n",
    "        self.step_checkpoint = step_checkpoint\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def fit_transform(self, continue_from_which_iteration=None):\n",
    "        path_to_save = './saved_files/SNE/'\n",
    "        if continue_from_which_iteration is not None:\n",
    "            paths_ = glob.glob(path_to_save+'X_transformed/*')\n",
    "            paths_ = [path_.split(\"\\\\\")[-1] for path_ in paths_]\n",
    "            paths_ = [path_.split(\".\")[0] for path_ in paths_]\n",
    "            name_of_variable = [path_ for path_ in paths_ if \"itr\"+str(continue_from_which_iteration) in path_][0]\n",
    "            X_transformed = self.load_variable(name_of_variable=name_of_variable, path=path_to_save+'X_transformed/')\n",
    "        else:\n",
    "            X_transformed = np.random.rand(self.n_components, self.n_training_images)  # --> rand in [0,1)\n",
    "            # save the information at checkpoints:\n",
    "            self.save_variable(variable=X_transformed, name_of_variable=\"X_transformed_initial\", path_to_save=path_to_save + 'X_transformed/')\n",
    "            if self.y is not None:\n",
    "                self.plot_embedding(X=X_transformed, y=self.y, path_save=path_to_save+\"training_plots/\", name_of_plot=\"X_transformed_0_.png\")\n",
    "        print(\"Calculating p for all pairs...\")\n",
    "        distance_matrix_originalSpace = self.get_distances_btw_points(data_matrix=self.X)\n",
    "        p_matrix = np.zeros((self.n_training_images, self.n_training_images))\n",
    "        for sample_index1 in range(self.n_training_images):\n",
    "            print(\"---processing for image \" + str(sample_index1))\n",
    "            sigma = 1 / (2 ** 0.5)\n",
    "            d_squared_of_row = (distance_matrix_originalSpace[sample_index1, :] ** 2) / (2 * (sigma ** 2))\n",
    "            d_squared_of_row_diagonalElementRemoved = np.delete(d_squared_of_row, sample_index1)   # remove the sample_index1-th column of minus_d_of_row\n",
    "            minus_d_squared_of_row_diagonalElementRemoved = -1 * d_squared_of_row_diagonalElementRemoved\n",
    "            minus_d_squared_of_row = -1 * d_squared_of_row\n",
    "            denominator = np.sum(np.exp(minus_d_squared_of_row_diagonalElementRemoved))\n",
    "            for sample_index2 in range(self.n_training_images):\n",
    "                if sample_index1 != sample_index2:\n",
    "                    numerator = np.exp(minus_d_squared_of_row[sample_index2])  # the sample_index2-th column of minus_d_of_row\n",
    "                    p = numerator / denominator\n",
    "                else:\n",
    "                    p = 0\n",
    "                p_matrix[sample_index1, sample_index2] = p\n",
    "        if continue_from_which_iteration is not None:\n",
    "            iteration_index = continue_from_which_iteration\n",
    "        else:\n",
    "            iteration_index = -1\n",
    "        cost_iters = np.zeros((self.step_checkpoint, 1))\n",
    "        update = 0\n",
    "        while True:\n",
    "            iteration_index = iteration_index + 1\n",
    "            #----- update alpha:\n",
    "            if iteration_index < 250:\n",
    "                alpha = 0.5   \n",
    "            else:\n",
    "                alpha = 0.8  \n",
    "            print(\"Iteration \" + str(iteration_index) + \"...\")\n",
    "            distance_matrix_embeddedSpace = self.get_distances_btw_points(data_matrix=X_transformed)\n",
    "            q_matrix = np.zeros((self.n_training_images, self.n_training_images))\n",
    "            for sample_index1 in range(self.n_training_images):\n",
    "                d_squared_of_row = (distance_matrix_embeddedSpace[sample_index1, :] ** 2)\n",
    "                d_squared_of_row_diagonalElementRemoved = np.delete(d_squared_of_row, sample_index1)   # remove the sample_index1-th column of minus_d_of_row\n",
    "                minus_d_squared_of_row_diagonalElementRemoved = -1 * d_squared_of_row_diagonalElementRemoved\n",
    "                minus_d_squared_of_row = -1 * d_squared_of_row\n",
    "                denominator = np.sum(np.exp(minus_d_squared_of_row_diagonalElementRemoved))\n",
    "                for sample_index2 in range(self.n_training_images):\n",
    "                    if sample_index1 != sample_index2:\n",
    "                        numerator = np.exp(minus_d_squared_of_row[sample_index2])  # the sample_index2-th column of minus_d_of_row\n",
    "                        q = numerator / denominator\n",
    "                    else:\n",
    "                        q = 0\n",
    "                    q_matrix[sample_index1, sample_index2] = q\n",
    "            for sample_index1 in range(self.n_training_images):\n",
    "                X_i_transformed_previousIteration = X_transformed[:, sample_index1].reshape((-1, 1))\n",
    "                gradient = np.zeros((self.n_components, 1))\n",
    "                for sample_index2 in range(self.n_training_images):\n",
    "                    X_j_transformed_previousIteration = X_transformed[:, sample_index2].reshape((-1, 1))\n",
    "                    p_ij = p_matrix[sample_index1, sample_index2]\n",
    "                    p_ji = p_matrix[sample_index2, sample_index1]\n",
    "                    q_ij = q_matrix[sample_index1, sample_index2]\n",
    "                    q_ji = q_matrix[sample_index2, sample_index1]\n",
    "                    gradient = gradient + (p_ij - q_ij + p_ji - q_ji) * (X_i_transformed_previousIteration - X_j_transformed_previousIteration)\n",
    "                gradient = gradient * 2\n",
    "                update = - (self.learning_rate * gradient) + (alpha * update)\n",
    "                X_i_transformed = X_i_transformed_previousIteration + update\n",
    "                X_transformed[:, sample_index1] = X_i_transformed.ravel()\n",
    "            #--- add some jitter:\n",
    "            if iteration_index < 50:\n",
    "                for sample_index in range(self.n_training_images):\n",
    "                    noise = np.random.normal(0, 0.1, self.n_components)\n",
    "                    X_transformed[:, sample_index] = X_transformed[:, sample_index] + noise\n",
    "            #--- calculate cost:\n",
    "            cost = 0\n",
    "            for sample_index1 in range(self.n_training_images):\n",
    "                for sample_index2 in range(self.n_training_images):\n",
    "                    if sample_index2 != sample_index1:\n",
    "                        p_ij = p_matrix[sample_index1, sample_index2]\n",
    "                        q_ij = q_matrix[sample_index1, sample_index2]\n",
    "                        if p_ij != 0 and q_ij != 0:\n",
    "                            cost = cost + (p_ij * np.log10(p_ij)) - (p_ij * np.log10(q_ij))\n",
    "            print(\"---- cost of this iteration: \" + str(cost))\n",
    "            index_to_save = iteration_index % self.step_checkpoint\n",
    "            cost_iters[index_to_save] = cost\n",
    "            # save the information at checkpoints:\n",
    "            if (iteration_index+1) % self.step_checkpoint == 0:\n",
    "                print(\"Saving the checkpoint in iteration #\" + str(iteration_index))\n",
    "                checkpoint_index = int(np.floor(iteration_index / self.step_checkpoint))\n",
    "                self.save_variable(variable=cost_iters, name_of_variable=\"cost_iters_itr\"+str(iteration_index)+\"_cp\"+str(checkpoint_index), path_to_save=path_to_save+'cost/')\n",
    "                self.save_np_array_to_txt(variable=cost_iters, name_of_variable=\"cost_iters_itr\"+str(iteration_index)+\"_cp\"+str(checkpoint_index), path_to_save=path_to_save+'cost/')\n",
    "                self.save_variable(variable=X_transformed, name_of_variable=\"X_transformed_itr\"+str(iteration_index)+\"_cp\"+str(checkpoint_index), path_to_save=path_to_save+'X_transformed/')\n",
    "                if self.y is not None:\n",
    "                    self.plot_embedding(X=X_transformed, y=self.y, path_save=path_to_save+\"training_plots/\", name_of_plot=\"X_transformed_itr\"+str(iteration_index)+\"_cp\"+str(checkpoint_index)+\".png\")\n",
    "            # --- check terminate:\n",
    "            if self.max_iterations is not None:\n",
    "                if iteration_index > self.max_iterations:\n",
    "                    return X_transformed\n",
    "\n",
    "    def fit_transform_symmetric(self, continue_from_which_iteration=None):\n",
    "        path_to_save = './saved_files/SNE_symmetric/'\n",
    "        if continue_from_which_iteration is not None:\n",
    "            paths_ = glob.glob(path_to_save+'X_transformed/*')\n",
    "            paths_ = [path_.split(\"\\\\\")[-1] for path_ in paths_]\n",
    "            paths_ = [path_.split(\".\")[0] for path_ in paths_]\n",
    "            name_of_variable = [path_ for path_ in paths_ if \"itr\"+str(continue_from_which_iteration) in path_][0]\n",
    "            X_transformed = self.load_variable(name_of_variable=name_of_variable, path=path_to_save+'X_transformed/')\n",
    "        else:\n",
    "            X_transformed = np.random.rand(self.n_components, self.n_training_images)  # --> rand in [0,1)\n",
    "            # save the information at checkpoints:\n",
    "            self.save_variable(variable=X_transformed, name_of_variable=\"X_transformed_initial\", path_to_save=path_to_save + 'X_transformed/')\n",
    "            if self.y is not None:\n",
    "                self.plot_embedding(X=X_transformed, y=self.y, path_save=path_to_save+\"training_plots/\", name_of_plot=\"X_transformed_0_.png\")\n",
    "        print(\"Calculating p for all pairs...\")\n",
    "        distance_matrix_originalSpace = self.get_distances_btw_points(data_matrix=self.X)\n",
    "        p_matrix = np.zeros((self.n_training_images, self.n_training_images))\n",
    "        for sample_index1 in range(self.n_training_images):\n",
    "            print(\"---processing for image \" + str(sample_index1))\n",
    "            sigma = 1 / (2 ** 0.5)\n",
    "            d_squared_of_row = (distance_matrix_originalSpace[sample_index1, :] ** 2) / (2 * (sigma ** 2))\n",
    "            d_squared_of_row_diagonalElementRemoved = np.delete(d_squared_of_row, sample_index1)   # remove the sample_index1-th column of minus_d_of_row\n",
    "            minus_d_squared_of_row_diagonalElementRemoved = -1 * d_squared_of_row_diagonalElementRemoved\n",
    "            minus_d_squared_of_row = -1 * d_squared_of_row\n",
    "            denominator = np.sum(np.exp(minus_d_squared_of_row_diagonalElementRemoved))\n",
    "            for sample_index2 in range(self.n_training_images):\n",
    "                if sample_index1 != sample_index2:\n",
    "                    numerator = np.exp(minus_d_squared_of_row[sample_index2])  # the sample_index2-th column of minus_d_of_row\n",
    "                    p = numerator / denominator\n",
    "                else:\n",
    "                    p = 0\n",
    "                p_matrix[sample_index1, sample_index2] = p\n",
    "        # make p symmetric:\n",
    "        p_matrix_symmetric = np.zeros((self.n_training_images, self.n_training_images))\n",
    "        for sample_index1 in range(self.n_training_images):\n",
    "            for sample_index2 in range(self.n_training_images):\n",
    "                p_matrix_symmetric[sample_index1, sample_index2] = (p_matrix[sample_index1, sample_index2] + p_matrix[sample_index2, sample_index1]) / (2 * self.n_training_images)\n",
    "        if continue_from_which_iteration is not None:\n",
    "            iteration_index = continue_from_which_iteration\n",
    "        else:\n",
    "            iteration_index = -1\n",
    "        cost_iters = np.zeros((self.step_checkpoint, 1))\n",
    "        update = 0\n",
    "        while True:\n",
    "            iteration_index = iteration_index + 1\n",
    "            #----- update alpha:\n",
    "            if iteration_index < 250:\n",
    "                alpha = 0.5   \n",
    "            else:\n",
    "                alpha = 0.8  \n",
    "            print(\"Iteration \" + str(iteration_index) + \"...\")\n",
    "            distance_matrix_embeddedSpace = self.get_distances_btw_points(data_matrix=X_transformed)\n",
    "            d_squared_of_all = (distance_matrix_embeddedSpace[:, :] ** 2)\n",
    "            minus_d_squared_of_all = -1 * d_squared_of_all\n",
    "            denominator = np.sum(np.exp(minus_d_squared_of_all))\n",
    "            denominator = denominator - np.sum(np.exp(np.diag(minus_d_squared_of_all))) #--> remove the diagonal elements\n",
    "            q_matrix = np.zeros((self.n_training_images, self.n_training_images))\n",
    "            for sample_index1 in range(self.n_training_images):\n",
    "                d_squared_of_row = (distance_matrix_embeddedSpace[sample_index1, :] ** 2)\n",
    "                minus_d_squared_of_row = -1 * d_squared_of_row\n",
    "                for sample_index2 in range(self.n_training_images):\n",
    "                    if sample_index1 != sample_index2:\n",
    "                        numerator = np.exp(minus_d_squared_of_row[sample_index2])  # the sample_index2-th column of minus_d_of_row\n",
    "                        q = numerator / denominator\n",
    "                    else:\n",
    "                        q = 0\n",
    "                    q_matrix[sample_index1, sample_index2] = q\n",
    "            for sample_index1 in range(self.n_training_images):\n",
    "                X_i_transformed_previousIteration = X_transformed[:, sample_index1].reshape((-1, 1))\n",
    "                gradient = np.zeros((self.n_components, 1))\n",
    "                for sample_index2 in range(self.n_training_images):\n",
    "                    X_j_transformed_previousIteration = X_transformed[:, sample_index2].reshape((-1, 1))\n",
    "                    p_ij = p_matrix_symmetric[sample_index1, sample_index2]\n",
    "                    q_ij = q_matrix[sample_index1, sample_index2]\n",
    "                    gradient = gradient + (p_ij - q_ij) * (X_i_transformed_previousIteration - X_j_transformed_previousIteration)\n",
    "                gradient = gradient * 4\n",
    "                update = - (self.learning_rate * gradient) + (alpha * update)\n",
    "                # update = - (self.learning_rate * gradient)\n",
    "                X_i_transformed = X_i_transformed_previousIteration + update\n",
    "                X_transformed[:, sample_index1] = X_i_transformed.ravel()\n",
    "            # #--- add some jitter:\n",
    "            # if iteration_index < 50:\n",
    "            #     for sample_index in range(self.n_training_images):\n",
    "            #         noise = np.random.normal(0, 0.1, self.n_components)\n",
    "            #         X_transformed[:, sample_index] = X_transformed[:, sample_index] + noise\n",
    "            #--- calculate cost:\n",
    "            cost = 0\n",
    "            for sample_index1 in range(self.n_training_images):\n",
    "                for sample_index2 in range(self.n_training_images):\n",
    "                    if sample_index2 != sample_index1:\n",
    "                        p_ij = p_matrix_symmetric[sample_index1, sample_index2]\n",
    "                        q_ij = q_matrix[sample_index1, sample_index2]\n",
    "                        if p_ij != 0 and q_ij != 0:\n",
    "                            cost = cost + (p_ij * np.log10(p_ij)) - (p_ij * np.log10(q_ij))\n",
    "            print(\"---- cost of this iteration: \" + str(cost))\n",
    "            index_to_save = iteration_index % self.step_checkpoint\n",
    "            cost_iters[index_to_save] = cost\n",
    "            # save the information at checkpoints:\n",
    "            if (iteration_index+1) % self.step_checkpoint == 0:\n",
    "                print(\"Saving the checkpoint in iteration #\" + str(iteration_index))\n",
    "                checkpoint_index = int(np.floor(iteration_index / self.step_checkpoint))\n",
    "                self.save_variable(variable=cost_iters, name_of_variable=\"cost_iters_itr\"+str(iteration_index)+\"_cp\"+str(checkpoint_index), path_to_save=path_to_save+'cost/')\n",
    "                self.save_np_array_to_txt(variable=cost_iters, name_of_variable=\"cost_iters_itr\"+str(iteration_index)+\"_cp\"+str(checkpoint_index), path_to_save=path_to_save+'cost/')\n",
    "                self.save_variable(variable=X_transformed, name_of_variable=\"X_transformed_itr\"+str(iteration_index)+\"_cp\"+str(checkpoint_index), path_to_save=path_to_save+'X_transformed/')\n",
    "                if self.y is not None:\n",
    "                    self.plot_embedding(X=X_transformed, y=self.y, path_save=path_to_save+\"training_plots/\", name_of_plot=\"X_transformed_itr\"+str(iteration_index)+\"_cp\"+str(checkpoint_index)+\".png\")\n",
    "            # --- check terminate:\n",
    "            if self.max_iterations is not None:\n",
    "                if iteration_index > self.max_iterations:\n",
    "                    return X_transformed\n",
    "\n",
    "    def get_distances_btw_points(self, data_matrix):\n",
    "        # data_matrix: rows are features and columns are samples\n",
    "        n_samples = data_matrix.shape[1]\n",
    "        distance_matrix = KNN(X=data_matrix.T, n_neighbors=n_samples-1, mode='distance', include_self=False, n_jobs=-1)\n",
    "        distance_matrix = distance_matrix.toarray()\n",
    "        return distance_matrix\n",
    "\n",
    "    def save_variable(self, variable, name_of_variable, path_to_save='./'):\n",
    "        # https://stackoverflow.com/questions/6568007/how-do-i-save-and-restore-multiple-variables-in-python\n",
    "        if not os.path.exists(path_to_save):  # https://stackoverflow.com/questions/273192/how-can-i-create-a-directory-if-it-does-not-exist\n",
    "            os.makedirs(path_to_save)\n",
    "        file_address = path_to_save + name_of_variable + '.pckl'\n",
    "        f = open(file_address, 'wb')\n",
    "        pickle.dump(variable, f)\n",
    "        f.close()\n",
    "\n",
    "    def load_variable(self, name_of_variable, path='./'):\n",
    "        # https://stackoverflow.com/questions/6568007/how-do-i-save-and-restore-multiple-variables-in-python\n",
    "        file_address = path + name_of_variable + '.pckl'\n",
    "        f = open(file_address, 'rb')\n",
    "        variable = pickle.load(f)\n",
    "        f.close()\n",
    "        return variable\n",
    "\n",
    "    def save_np_array_to_txt(self, variable, name_of_variable, path_to_save='./'):\n",
    "        if type(variable) is list:\n",
    "            variable = np.asarray(variable)\n",
    "        # https://stackoverflow.com/questions/22821460/numpy-save-2d-array-to-text-file/22822701\n",
    "        if not os.path.exists(path_to_save):  # https://stackoverflow.com/questions/273192/how-can-i-create-a-directory-if-it-does-not-exist\n",
    "            os.makedirs(path_to_save)\n",
    "        file_address = path_to_save + name_of_variable + '.txt'\n",
    "        np.set_printoptions(threshold=np.inf, linewidth=np.inf)  # turn off summarization, line-wrapping\n",
    "        with open(file_address, 'w') as f:\n",
    "            f.write(np.array2string(variable, separator=', '))\n",
    "\n",
    "    def plot_embedding(self, X, y, path_save=None, name_of_plot=None):\n",
    "        # X: column-wise\n",
    "        color_map = plt.cm.jet  #--> hsv, brg (good for S curve), rgb, jet, gist_ncar (good for one blob), tab10, Set1, rainbow, Spectral #--> https://matplotlib.org/3.2.1/tutorials/colors/colormaps.html\n",
    "        plt.scatter(X[0, :], X[1, :], c=y, cmap=color_map, edgecolors='k')\n",
    "        classes = [str(i) for i in range(len(np.unique(y)))]\n",
    "        n_classes = len(classes)\n",
    "        cbar = plt.colorbar(boundaries=np.arange(n_classes+1)-0.5)\n",
    "        cbar.set_ticks(np.arange(n_classes))\n",
    "        cbar.set_ticklabels(classes)\n",
    "        if path_save is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            if not os.path.exists(path_save):\n",
    "                os.makedirs(path_save)\n",
    "            plt.savefig(path_save+name_of_plot)\n",
    "            plt.close()\n",
    "\n",
    "    def transform_outOfSample(self, X_test, which_training_iteration_to_load, symmetric_method=False):\n",
    "        # X_test, X_test_transformed: rows are features and columns are samples\n",
    "        ##### read the training embedding:\n",
    "        X_transformed = self.read_the_saved_training_embedding(which_training_iteration_to_load, symmetric_method)\n",
    "        X_transformed = X_transformed.T  #--> make it row-wise\n",
    "        ##### embedding the out-of-sample:\n",
    "        kernel_X_X = pairwise_kernels(X=self.X.T, Y=self.X.T, metric=\"rbf\")\n",
    "        kernel_Xtest_X = pairwise_kernels(X=X_test.T, Y=self.X.T, metric=\"rbf\")\n",
    "        n_training_samples = self.X.shape[1]\n",
    "        K = np.zeros((n_training_samples, n_training_samples))\n",
    "        for sample_index in range(n_training_samples):\n",
    "            K[sample_index, :] = kernel_X_X[sample_index, :] * (1 / np.sum(kernel_X_X[sample_index, :]))\n",
    "        n_test_samples = X_test.shape[1]\n",
    "        K_test = np.zeros((n_test_samples, n_training_samples))\n",
    "        for test_sample_index in range(n_test_samples):\n",
    "            K_test[test_sample_index, :] = kernel_Xtest_X[test_sample_index, :] * (1 / np.sum(kernel_Xtest_X[test_sample_index, :]))\n",
    "        A = np.linalg.pinv(K) @ X_transformed\n",
    "        X_test_transformed = K_test @ A\n",
    "        X_test_transformed = X_test_transformed.T  #--> make it column-wise\n",
    "        return X_test_transformed\n",
    "\n",
    "    def read_the_saved_training_embedding(self, which_training_iteration_to_load, symmetric_method=False):\n",
    "        # X_transformed: column-wise\n",
    "        if not symmetric_method:\n",
    "            path_to_save = './saved_files/SNE/'\n",
    "        else:\n",
    "            path_to_save = './saved_files/SNE_symmetric/'\n",
    "        paths_ = glob.glob(path_to_save+'X_transformed/*')\n",
    "        paths_ = [path_.split(\"\\\\\")[-1] for path_ in paths_]\n",
    "        paths_ = [path_.split(\".\")[0] for path_ in paths_]\n",
    "        name_of_variable = [path_ for path_ in paths_ if \"itr\"+str(which_training_iteration_to_load) in path_][0]\n",
    "        X_transformed = self.load_variable(name_of_variable=name_of_variable, path=path_to_save+'X_transformed/')\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858e2b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
